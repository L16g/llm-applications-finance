{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import my_secrets\n",
    "import openai\n",
    "import requests\n",
    "import time\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "\n",
    "# model used to generate responses and dictate tokenization\n",
    "model = 'gpt-3.5-turbo' # for better performance at a higher price point use: 'gpt-4'\n",
    "openai.api_key = my_secrets.OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://platform.openai.com/playground?mode=chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    try:\n",
    "        encoding = tiktoken.get_encoding(encoding_name)\n",
    "    except ValueError:\n",
    "        encoding = tiktoken.encoding_for_model(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"Cleans up earnings transcript formatting\"\"\"\n",
    "    return ' '.join(text.splitlines()).strip() # cleaning up formatting\n",
    "    \n",
    "\n",
    "def set_user_content(company_name: str, quarter: int, year: int, transcript: str) -> str:\n",
    "    \"\"\"Sets the task for the LLM and delivers the transcript\"\"\"\n",
    "    # set the initial context\n",
    "    context = f'''Your job is to return a single number between 1 and 20 for the quarter {quarter} {year} earnings release by {company_name}. \n",
    "    A score of 1 means the text had extremely poor sentiment, while a score of 20 means the text had extremely positive sentiment.  \n",
    "    Please only return a single number. No additional response is required.\n",
    "    Here is the transcript: \"\"\"{transcript}\"\"\"\n",
    "    '''\n",
    "\n",
    "    user_content = {\"role\": \"user\", \"content\": clean_text(context)}\n",
    "\n",
    "    return user_content\n",
    "\n",
    "def generate_sub_content(transcript, model):\n",
    "    \"\"\"Breaks up a transcript into individual parts to fit the context window of the LLM.\"\"\"\n",
    "    sub_contexts = []\n",
    "    n = num_tokens_from_string(transcript, model) + 1000 # space for setting the context and metadata\n",
    "    # if it is more than 16k...\n",
    "    parts = math.ceil(n / 16000) + 1 # calculate the number of times we'll break up the text\n",
    "\n",
    "    # determine breakpoints\n",
    "    breakpoint = math.ceil( n / parts )\n",
    "    token_idx = [(p+1) * breakpoint for p in range((parts-1))] # translate breakpoint to index\n",
    "    l_sentences = transcript.split('. ') # ensure we end the sub-transcript with the end of a sentence.\n",
    "\n",
    "    # generate \n",
    "    l_idx = []\n",
    "\n",
    "    for t in range(len(token_idx) + 1):\n",
    "      n_sentences = np.array([num_tokens_from_string(s, model) for s in l_sentences])\n",
    "      sum_sentences = n_sentences.cumsum()\n",
    "\n",
    "      if t < len(token_idx):\n",
    "        last_valid = sum_sentences[sum_sentences < token_idx[t]][-1]\n",
    "      else:\n",
    "        last_valid = sum_sentences[-1]\n",
    "      last_idx = np.where(sum_sentences == last_valid)[0][0]\n",
    "      l_idx.append(last_idx)\n",
    "\n",
    "      if t > 0:\n",
    "        first_idx = l_idx[t-1]\n",
    "      else:\n",
    "        first_idx = 0\n",
    "\n",
    "      sub_context = '. '.join(l_sentences[first_idx:last_idx+1])\n",
    "      sub_contexts.append(sub_context)\n",
    "      \n",
    "    return sub_contexts\n",
    "\n",
    "calibration_init = \"Your job is to return a single number between 1 and 20 for the provided text. A score of 1 means the text had extremely poor sentiment, while a score of 20 means the text had extremely positive sentiment. Please only return a single number. No additional response is required. Here is the text to analyze:\"\n",
    "\n",
    "def initialize_message(system_content):\n",
    "  \"\"\"We will need to clear out the message box every time we hit the API\"\"\"\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": system_content},\n",
    "    {\"role\": \"user\", \"content\": calibration_init + f'\"\"\"{poor_sentiment2}\"\"\"' },\n",
    "    {\"role\": \"assistant\", \"content\": \"2\"},\n",
    "    {\"role\": \"user\", \"content\": \"That is a good response. I have another one for you to analyze.\" + calibration_init + f'\"\"\"{positive_sentiment}\"\"\"' },\n",
    "    {\"role\": \"assistant\", \"content\": \"19\"},\n",
    "    {\"role\": \"user\", \"content\": \"That is a good response. I have another one for you to analyze.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Thank you. Ready when you are.\"},\n",
    "  ]\n",
    "  return messages\n",
    "\n",
    "@retry(wait=wait_random_exponential(multiplier=1, max=40), stop=stop_after_attempt(3))\n",
    "def chat_completion_request(messages, model):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": \"Bearer \" + openai.api_key,\n",
    "    }\n",
    "    json_data = {\n",
    "       \"model\": model + '-16k', \n",
    "       \"messages\": messages,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            \"https://api.openai.com/v1/chat/completions\",\n",
    "            headers=headers,\n",
    "            json=json_data,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(\"Unable to generate ChatCompletion response\")\n",
    "        print(f\"Exception: {e}\")\n",
    "    \n",
    "    return response\n",
    "\n",
    "# a few global variables\n",
    "\n",
    "# redefining the role of the LLM. Default is helpful assistant. We want to turn that into \"stock research analyst\"\n",
    "# this message appears at the beginning of every request\n",
    "system_content = clean_text(\n",
    "    '''You are a sentiment analysis machine used to determine the sentiment of summaries of companies' earnings call transcripts.\n",
    "    You will receive a summary text. You will return a single number between 1 and 20, with 1 being extremely poor sentiment and 20 being euphoric sentiment, describing the text.  \n",
    "    The text to be analyzed is delimited by triple quotes.\n",
    "    '''\n",
    ")\n",
    "\n",
    "\n",
    "# calibration\n",
    "\n",
    "## poor sentiment\n",
    "poor_sentiment = clean_text('''\n",
    "In this earnings call transcript, several key points regarding the company's financial performance and strategies are highlighted:\n",
    "- The company starts by announcing the withdrawal of previously communicated financial guidance, likely due to the uncertainty caused by the events in March.\n",
    "- The management emphasizes their commitment to serving clients and communities, even during challenging times. \n",
    "- The company experienced significant deposit outflows in March but notes that deposits stabilized by the end of March. \n",
    "- The company's capital position is described as well-capitalized, with specific Tier 1 leverage, common equity Tier 1, and total risk-based capital ratios. \n",
    "- The company mentions the suspension of dividends on common and preferred stock for prudent capital management.\n",
    "- The company reports declines in sales and profitability from customer churn. \n",
    "- The company outlines several strategies to strengthen its business, including a workforce reduction and executive compensation reduction while maintaining a commitment to client service.\n",
    "Overall, the transcript indicates a challenging period marked by deposit outflows, the need for additional liquidity, and a focus on stabilizing the company's financial position. The suspension of dividends and workforce reduction reflect measures taken to address these challenges while maintaining a commitment to clients and communities.\n",
    "''')\n",
    "\n",
    "poor_sentiment2 = clean_text(\n",
    "'''\n",
    "In this earnings call transcript, several key points regarding the company's financial performance and strategies are highlighted:\n",
    "- The management emphasizes their commitment to serving clients and communities, even during challenging times. \n",
    "- The company experienced modest growth and believes they will still fall within guidance for the full year. \n",
    "- The company's capital position is described as well-capitalized.\n",
    "- The company reports little growth in earnings.\n",
    "- The company outlines several strategies to strengthen its business, including controlling expenses and being more prudent investors of its capital.\n",
    "Overall, the transcript indicates a challenging period marked by the need for additional liquidity, and a focus on stabilizing the company's financial position. \n",
    "The suspension of dividends and workforce reduction reflect measures taken to address these challenges while maintaining a commitment to clients and communities.\n",
    "'''\n",
    ")\n",
    "\n",
    "## great sentiment\n",
    "positive_sentiment = clean_text('''\n",
    "In the earnings call transcript, the following key points are highlighted:\n",
    "- The company beat expectations and raised guidance for the next quarter and remainder of the year.\n",
    "- Total ARR (Annual Recurring Revenue) growth for the company was 47% in the third quarter, with organic ARR growth of 37%.\n",
    "- Organic ARR growth for the company in Q3 was 37%, demonstrating consistent growth.\n",
    "- The company achieved strong new logo acquisition and reached over 57,000 total active customers by the end of Q3.\n",
    "- Growth was seen in all major geographies and across all of the company's top 10 commercial industries.\n",
    "- Commercial markets made up nearly 75% of total bookings.\n",
    "- The company attributes its growth to the expansion of devices in global enterprises.\n",
    "- The company's platform capabilities are broadening to address IT and security challenges.\n",
    "- The company ended the quarter with 25 million devices on its platform, representing 34% year-over-year growth.\n",
    "\n",
    "In summary, the company reported strong growth in ARR, revenue, and the number of devices on its platform. \n",
    "The company's performance was consistent across various geographies and industries. \n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`EarningsTranscriptData.txt` is a text file, delimited by commas with the following columns: `symbol`, `year`, `quarter`, `chunk`, `response`.\n",
    "If you run `get_gpt_summaries.ipynb`, it generates the data in appropriate format. See that notebook for details on each column. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('gpt_summaries.csv').groupby(['symbol', 'year', 'quarter'])['response'].apply(lambda x: ','.join(x)).reset_index()\n",
    "xref = pd.read_csv('company_xref.csv')\n",
    "df = pd.merge(df, xref, how='left', on='symbol').rename({'registrantName':'company_name'}, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize empty list to store responses\n",
    "sentiment_responses = [None] * df.shape[0]\n",
    "\n",
    "for i in range(len(sentiment_responses)):\n",
    "  ticker = df.loc[i,'symbol']\n",
    "  quarter = df.loc[i,'quarter']\n",
    "  year = df.loc[i,'year']\n",
    "  transcript = df.loc[i,'response']\n",
    "  if len(transcript) < 1:\n",
    "    continue\n",
    "  company_name = xref[xref.symbol == ticker].registrantName.values[0]\n",
    "  \n",
    "  # initialize message dict with `system`\n",
    "  messages = initialize_message(system_content=system_content)\n",
    "  # update messages with user context and transcript\n",
    "  messages.append(set_user_content(company_name, quarter, year, transcript))\n",
    "  # hit api with messages, get response\n",
    "  json_resp = chat_completion_request(messages=messages, model=model)\n",
    "  try:\n",
    "    resp = dict(json_resp.json())['choices'][0]['message']['content'] # try to extract content\n",
    "  except KeyError:\n",
    "    print(f'WARNING: {ticker} {quarter}Q{year} skipped due to bad response.')\n",
    "    continue # move on, try again later\n",
    "  except requests.JSONDecodeError:\n",
    "    print(f'WARNING: {ticker} {quarter}Q{year} skipped due to bad response.')\n",
    "    continue # move on, try again later\n",
    "  else:\n",
    "    resp = dict(json_resp.json())['choices'][0]['message']['content'] # we just want the content\n",
    "  # parse response and store with data in dataframe\n",
    "  sentiment_responses[i] = resp\n",
    "  df['sentiment_score'] = sentiment_responses\n",
    "  df.to_csv('gpt_sentiment2.csv', index=False)\n",
    "  time.sleep(5) # just so we don't murder the api\n",
    "  print(f'Completed {ticker} {quarter}Q{year}.')\n",
    "      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
