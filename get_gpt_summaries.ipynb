{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import my_secrets\n",
    "import openai\n",
    "import requests\n",
    "import time\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "\n",
    "# model used to generate responses and dictate tokenization\n",
    "model = 'gpt-3.5-turbo' # for better performance at a higher price point use: 'gpt-4'\n",
    "\n",
    "openai.api_key = my_secrets.OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://platform.openai.com/playground?mode=chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    try:\n",
    "        encoding = tiktoken.get_encoding(encoding_name)\n",
    "    except ValueError:\n",
    "        encoding = tiktoken.encoding_for_model(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"Cleans up earnings transcript formatting\"\"\"\n",
    "    return ' '.join(text.splitlines()).strip() # cleaning up formatting\n",
    "    \n",
    "\n",
    "def set_user_content(company_name: str, quarter: int, year: int, transcript: str) -> str:\n",
    "    \"\"\"Sets the task for the LLM and delivers the transcript\"\"\"\n",
    "    # set the initial context\n",
    "    context = f'''Your job is to summarize the following transcript for the quarter {quarter} {year} earnings release by {company_name}. \n",
    "    Pay specific attention to discussed items that impact sales, margins and earnings. \n",
    "    Identify what the sell side analysts focused on the most in the Q&A portion, if there is one.\n",
    "    Here is the transcript: \"\"\"{transcript}\"\"\"\n",
    "    '''\n",
    "\n",
    "    user_content = {\"role\": \"user\", \"content\": clean_text(context)}\n",
    "\n",
    "    return user_content\n",
    "\n",
    "def generate_sub_content(transcript, model):\n",
    "    \"\"\"Breaks up a transcript into individual parts to fit the context window of the LLM.\"\"\"\n",
    "    sub_contexts = []\n",
    "    n = num_tokens_from_string(transcript, model) + 1000 # space for setting the context and metadata\n",
    "    # if it is more than 16k...\n",
    "    parts = math.ceil(n / 16000) + 1 # calculate the number of times we'll break up the text\n",
    "\n",
    "    # determine breakpoints\n",
    "    breakpoint = math.ceil( n / parts )\n",
    "    token_idx = [(p+1) * breakpoint for p in range((parts-1))] # translate breakpoint to index\n",
    "    l_sentences = transcript.split('. ') # ensure we end the sub-transcript with the end of a sentence.\n",
    "\n",
    "    # generate \n",
    "    l_idx = []\n",
    "\n",
    "    for t in range(len(token_idx) + 1):\n",
    "      n_sentences = np.array([num_tokens_from_string(s, model) for s in l_sentences])\n",
    "      sum_sentences = n_sentences.cumsum()\n",
    "\n",
    "      if t < len(token_idx):\n",
    "        last_valid = sum_sentences[sum_sentences < token_idx[t]][-1]\n",
    "      else:\n",
    "        last_valid = sum_sentences[-1]\n",
    "      last_idx = np.where(sum_sentences == last_valid)[0][0]\n",
    "      l_idx.append(last_idx)\n",
    "\n",
    "      if t > 0:\n",
    "        first_idx = l_idx[t-1]\n",
    "      else:\n",
    "        first_idx = 0\n",
    "\n",
    "      sub_context = '. '.join(l_sentences[first_idx:last_idx+1])\n",
    "      sub_contexts.append(sub_context)\n",
    "      \n",
    "    return sub_contexts\n",
    "\n",
    "def initialize_message(system_content):\n",
    "  \"\"\"We will need to clear out the message box every time we hit the API\"\"\"\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": system_content}\n",
    "  ]\n",
    "  return messages\n",
    "\n",
    "# a few global variables\n",
    "\n",
    "# redefining the role of the LLM. Default is helpful assistant. We want to turn that into \"stock research analyst\"\n",
    "# this message appears at the beginning of every request\n",
    "system_content = clean_text(\n",
    "    '''You are an intelligent stock research analyst who gives opinions on the performance of public companies in the United States.   \n",
    "    You are particularly good at distilling information from earnings transcripts to the most relevant pieces. \n",
    "    Earnings transcripts generally have two sections. One section entails prepared remarks by the company's management team, which covers the last quarter or year's performance, and usually includes guidance for the upcoming quarter or remainder of the year.\n",
    "    The second section is a question and answer session between the company's management team and Wall Street sell-side analysts. The Q&A segment has more dialogue.\n",
    "    You will be provided part of the transcript which may include one or both sections, delimited by triple quotes.  Only use the data from the transcript provided to briefly summarize the content.\n",
    "    '''\n",
    ")\n",
    "\n",
    "\n",
    "@retry(wait=wait_random_exponential(multiplier=1, max=40), stop=stop_after_attempt(3))\n",
    "def chat_completion_request(messages, model):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": \"Bearer \" + openai.api_key,\n",
    "    }\n",
    "    json_data = {\n",
    "       \"model\": model + '-16k', \n",
    "       \"messages\": messages,\n",
    "\n",
    "       }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            \"https://api.openai.com/v1/chat/completions\",\n",
    "            headers=headers,\n",
    "            json=json_data,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(\"Unable to generate ChatCompletion response\")\n",
    "        print(f\"Exception: {e}\")\n",
    "    \n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`EarningsTranscriptData.txt` is a text file, delimited by commas with the following columns: `symbol`, `quarter`, `year`, `date`, `content`.\n",
    "If you run `earnings_extraction.py`, it generates the data in appropriate format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('EarningsTranscriptData.txt')\n",
    "xref = pd.read_csv('company_xref.csv')\n",
    "\n",
    "df = pd.merge(df, xref, how='left', on='symbol').rename({'registrantName':'company_name'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fiscal years and quarters to extract\n",
    "quarters = [1,2,3,4]\n",
    "years = [2018, 2019, 2020, 2021, 2022]\n",
    "holdings = ['WMT', 'EQIX', 'CMG', 'MCHP', 'VTRS', 'RMD', 'PEG', 'PEP', 'CI',\n",
    "            'HON', 'BALL', 'CPB', 'MRO', 'NVDA', 'PARA', 'MTCH', 'ETSY', 'EMN',\n",
    "            'WBD', 'CINF', 'LDOS', 'CE', 'SBAC', 'NOW', 'MDLZ']\n",
    "\n",
    "completed = pd.read_csv('gpt_summaries.csv')\n",
    "\n",
    "all_data = []\n",
    "for ticker in holdings:\n",
    "  for year in years:\n",
    "    for quarter in quarters:\n",
    "\n",
    "      # pull transcript from library\n",
    "      _transcript = df[(df.symbol == ticker) & (df.quarter == quarter) & (df.year == year)]['content'].values\n",
    "      # not all companies in sample report in all years for all quarters; loop continues if no transcript found\n",
    "      if len(_transcript) < 1:\n",
    "        continue\n",
    "      else:\n",
    "        transcript = _transcript[0]\n",
    "\n",
    "      company_name = xref[xref.symbol == ticker].registrantName.values[0]\n",
    "      # break up transcript into parts\n",
    "      l_sc = generate_sub_content(transcript, model)\n",
    "      #print(f'{ticker} {quarter}Q{year} has {len(l_sc)} chunks.')\n",
    "\n",
    "      # check to see if already completed...\n",
    "      n_complete = completed[(completed.symbol == ticker) & (completed.quarter == quarter) & (completed.year == year)].shape[0]\n",
    "      if n_complete >= len(l_sc):\n",
    "        print(f'Skipping {ticker} {quarter}Q{year}.')\n",
    "        continue\n",
    "      elif n_complete == 0:\n",
    "        print(f'Starting {ticker} {quarter}Q{year}')\n",
    "      else:\n",
    "        l_sc[n_complete:] # only run the chunks that have not been saved\n",
    "        print(f'Partial detected. Starting with chunk {n_complete} out of {len(l_sc)}.')\n",
    "      for sc in range(len(l_sc)):\n",
    "        # initialize message dict with `system`\n",
    "        messages = initialize_message(system_content=system_content)\n",
    "        # update messages with user context and transcript\n",
    "        messages.append(set_user_content(company_name, quarter, year, transcript))\n",
    "        # hit api with messages, get response\n",
    "        json_resp = chat_completion_request(messages=messages, model=model)\n",
    "        try:\n",
    "          resp = dict(json_resp.json())['choices'][0]['message']['content'] # try to extract content\n",
    "        except KeyError:\n",
    "          print(f'WARNING: {ticker} {quarter}Q{year} skipped due to bad response.')\n",
    "          continue # move on, try again later\n",
    "        except requests.JSONDecodeError:\n",
    "          print(f'WARNING: {ticker} {quarter}Q{year} skipped due to bad response.')\n",
    "          continue # move on, try again later\n",
    "        else:\n",
    "          resp = dict(json_resp.json())['choices'][0]['message']['content'] # we just want the content\n",
    "        # parse response and store with data in dataframe\n",
    "        _df = pd.DataFrame.from_dict({'symbol':ticker, 'year': year, 'quarter': quarter, 'chunk': sc, 'response': resp}, orient='index').T\n",
    "        all_data.append(_df)\n",
    "        time.sleep(10) # just so we don't murder the api\n",
    "      print(f'Completed {ticker} {quarter}Q{year}.')\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adds completed responses to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([completed, pd.concat(all_data)]).to_csv('gpt_summaries.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>chunk</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WMT</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>In the Q1 2018 earnings release, Walmart repor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WMT</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>In the transcript of Walmart's Q1 2018 earning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WMT</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Walmart reported solid results for the second ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WMT</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>During the second quarter of fiscal 2018, Walm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WMT</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>In the prepared remarks section of the transcr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>MDLZ</td>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Mondelez International reported a strong secon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>MDLZ</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Mondelez International reported a strong quart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>MDLZ</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Mondelez International, Inc. reported strong p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>MDLZ</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Mondelez International had a strong performanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>MDLZ</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Mondelez International reported strong financi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>964 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    symbol  year  quarter  chunk  \\\n",
       "0      WMT  2018        1      0   \n",
       "1      WMT  2018        1      1   \n",
       "2      WMT  2018        2      0   \n",
       "3      WMT  2018        2      1   \n",
       "4      WMT  2018        3      0   \n",
       "..     ...   ...      ...    ...   \n",
       "959   MDLZ  2022        2      1   \n",
       "960   MDLZ  2022        3      0   \n",
       "961   MDLZ  2022        3      1   \n",
       "962   MDLZ  2022        4      0   \n",
       "963   MDLZ  2022        4      1   \n",
       "\n",
       "                                              response  \n",
       "0    In the Q1 2018 earnings release, Walmart repor...  \n",
       "1    In the transcript of Walmart's Q1 2018 earning...  \n",
       "2    Walmart reported solid results for the second ...  \n",
       "3    During the second quarter of fiscal 2018, Walm...  \n",
       "4    In the prepared remarks section of the transcr...  \n",
       "..                                                 ...  \n",
       "959  Mondelez International reported a strong secon...  \n",
       "960  Mondelez International reported a strong quart...  \n",
       "961  Mondelez International, Inc. reported strong p...  \n",
       "962  Mondelez International had a strong performanc...  \n",
       "963  Mondelez International reported strong financi...  \n",
       "\n",
       "[964 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "completed = pd.read_csv('gpt_summaries.csv')\n",
    "completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you do with the above sub-summaries is up to you.  You could group by ticker, year, and quarter and resend to the LLM with a prompt that asks it to combine the summaries in a way that keeps all unique information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
